{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e213adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the PySpark libraries\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "634c755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Spark session\n",
    "\n",
    "spark = SparkSession.builder.appName('practice_spark').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df7d7608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-N7GS2PFU:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>practice_spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1cc6199ca90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the Spark Session\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8839d953",
   "metadata": {},
   "source": [
    "- In this when we are executing in local we always see there is one cluster but when we can create multiple clusters and instances when we are working on cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82f717f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('50_Startups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0c1acc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f834594b",
   "metadata": {},
   "source": [
    "### PySpark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e44af363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataframe by loading csv file\n",
    "\n",
    "df_movie = spark.read.csv('50_Startups.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c41789ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's another way to read the dataset\n",
    "\n",
    "df_movie = spark.read.option('header','true').csv('50_Startups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cccd34c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+---------------+----------+---------+\n",
      "|R&D Spend|Administration|Marketing Spend|     State|   Profit|\n",
      "+---------+--------------+---------------+----------+---------+\n",
      "| 165349.2|      136897.8|       471784.1|  New York|192261.83|\n",
      "| 162597.7|     151377.59|      443898.53|California|191792.06|\n",
      "|153441.51|     101145.55|      407934.54|   Florida|191050.39|\n",
      "|144372.41|     118671.85|      383199.62|  New York|182901.99|\n",
      "|142107.34|      91391.77|      366168.42|   Florida|166187.94|\n",
      "| 131876.9|      99814.71|      362861.36|  New York|156991.12|\n",
      "|134615.46|     147198.87|      127716.82|California|156122.51|\n",
      "|130298.13|     145530.06|      323876.68|   Florida| 155752.6|\n",
      "|120542.52|     148718.95|      311613.29|  New York|152211.77|\n",
      "|123334.88|     108679.17|      304981.62|California|149759.96|\n",
      "|101913.08|     110594.11|      229160.95|   Florida|146121.95|\n",
      "|100671.96|      91790.61|      249744.55|California| 144259.4|\n",
      "| 93863.75|     127320.38|      249839.44|   Florida|141585.52|\n",
      "| 91992.39|     135495.07|      252664.93|California|134307.35|\n",
      "|119943.24|     156547.42|      256512.92|   Florida|132602.65|\n",
      "|114523.61|     122616.84|      261776.23|  New York|129917.04|\n",
      "| 78013.11|     121597.55|      264346.06|California|126992.93|\n",
      "| 94657.16|     145077.58|      282574.31|  New York|125370.37|\n",
      "| 91749.16|     114175.79|      294919.57|   Florida| 124266.9|\n",
      "|  86419.7|     153514.11|              0|  New York|122776.86|\n",
      "+---------+--------------+---------------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movie.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a40e591b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the datatype of the dataframe\n",
    "\n",
    "type(df_movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be32b7a2",
   "metadata": {},
   "source": [
    "- Here we can see the type of the dataframe is pyspark.sql.dataframe. But in case of pandas the dataframe is type of pandas.core.frame.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42f6331c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R&D Spend', 'Administration', 'Marketing Spend', 'State', 'Profit']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can check the columns by using the same command as we use in pandas dataframe\n",
    "\n",
    "df_movie.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd0ce5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(R&D Spend='165349.2', Administration='136897.8', Marketing Spend='471784.1', State='New York', Profit='192261.83'),\n",
       " Row(R&D Spend='162597.7', Administration='151377.59', Marketing Spend='443898.53', State='California', Profit='191792.06'),\n",
       " Row(R&D Spend='153441.51', Administration='101145.55', Marketing Spend='407934.54', State='Florida', Profit='191050.39'),\n",
       " Row(R&D Spend='144372.41', Administration='118671.85', Marketing Spend='383199.62', State='New York', Profit='182901.99'),\n",
       " Row(R&D Spend='142107.34', Administration='91391.77', Marketing Spend='366168.42', State='Florida', Profit='166187.94')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the top 5 data\n",
    "\n",
    "df_movie.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbd90734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- R&D Spend: string (nullable = true)\n",
      " |-- Administration: string (nullable = true)\n",
      " |-- Marketing Spend: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Profit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printSchema() function is just like info() in pandas which gives datatypes of columns\n",
    "\n",
    "df_movie.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47f7b11",
   "metadata": {},
   "source": [
    "- By default the datatype of features considers as string.\n",
    "- In order to make it correct we can use parameter inferschema which will consider the features datatype correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d45d6332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- R&D Spend: double (nullable = true)\n",
      " |-- Administration: double (nullable = true)\n",
      " |-- Marketing Spend: double (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Profit: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movie = spark.read.csv('50_Startups.csv', header = True, inferSchema = True)\n",
    "df_movie.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dae72d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+\n",
      "|R&D Spend|     State|   Profit|\n",
      "+---------+----------+---------+\n",
      "| 165349.2|  New York|192261.83|\n",
      "| 162597.7|California|191792.06|\n",
      "|153441.51|   Florida|191050.39|\n",
      "|144372.41|  New York|182901.99|\n",
      "|142107.34|   Florida|166187.94|\n",
      "| 131876.9|  New York|156991.12|\n",
      "|134615.46|California|156122.51|\n",
      "|130298.13|   Florida| 155752.6|\n",
      "|120542.52|  New York|152211.77|\n",
      "|123334.88|California|149759.96|\n",
      "+---------+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select any perticular column\n",
    "\n",
    "df_movie.select(['R&D Spend','State','Profit']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "839f6238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('R&D Spend', 'double'),\n",
       " ('Administration', 'double'),\n",
       " ('Marketing Spend', 'double'),\n",
       " ('State', 'string'),\n",
       " ('Profit', 'double')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the datatypes\n",
    "\n",
    "df_movie.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a02499b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+----------+------------------+\n",
      "|summary|        R&D Spend|    Administration|   Marketing Spend|     State|            Profit|\n",
      "+-------+-----------------+------------------+------------------+----------+------------------+\n",
      "|  count|               50|                50|                50|        50|                50|\n",
      "|   mean|73721.61559999999|121344.63959999995|211025.09780000005|      null|112012.63920000002|\n",
      "| stddev|45902.25648230754|28017.802755488683|122290.31072584528|      null|40306.180337650534|\n",
      "|    min|              0.0|          51283.14|               0.0|California|           14681.4|\n",
      "|    max|         165349.2|         182645.56|          471784.1|  New York|         192261.83|\n",
      "+-------+-----------------+------------------+------------------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movie.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eb61c2",
   "metadata": {},
   "source": [
    "### Adding columns in PySpark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c9b72f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+---------------+----------+---------+------------+\n",
      "|R&D Spend|Administration|Marketing Spend|     State|   Profit|Profit+10000|\n",
      "+---------+--------------+---------------+----------+---------+------------+\n",
      "| 165349.2|      136897.8|       471784.1|  New York|192261.83|   202261.83|\n",
      "| 162597.7|     151377.59|      443898.53|California|191792.06|   201792.06|\n",
      "|153441.51|     101145.55|      407934.54|   Florida|191050.39|   201050.39|\n",
      "|144372.41|     118671.85|      383199.62|  New York|182901.99|   192901.99|\n",
      "|142107.34|      91391.77|      366168.42|   Florida|166187.94|   176187.94|\n",
      "| 131876.9|      99814.71|      362861.36|  New York|156991.12|   166991.12|\n",
      "|134615.46|     147198.87|      127716.82|California|156122.51|   166122.51|\n",
      "|130298.13|     145530.06|      323876.68|   Florida| 155752.6|    165752.6|\n",
      "|120542.52|     148718.95|      311613.29|  New York|152211.77|   162211.77|\n",
      "|123334.88|     108679.17|      304981.62|California|149759.96|   159759.96|\n",
      "+---------+--------------+---------------+----------+---------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movie = df_movie.withColumn('Profit+10000', df_movie.Profit + 10000)\n",
    "df_movie.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f6ea9b",
   "metadata": {},
   "source": [
    "### Dropping columns in PySpark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a6a9bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+---------------+----------+---------+\n",
      "|R&D Spend|Administration|Marketing Spend|     State|   Profit|\n",
      "+---------+--------------+---------------+----------+---------+\n",
      "| 165349.2|      136897.8|       471784.1|  New York|192261.83|\n",
      "| 162597.7|     151377.59|      443898.53|California|191792.06|\n",
      "|153441.51|     101145.55|      407934.54|   Florida|191050.39|\n",
      "|144372.41|     118671.85|      383199.62|  New York|182901.99|\n",
      "|142107.34|      91391.77|      366168.42|   Florida|166187.94|\n",
      "| 131876.9|      99814.71|      362861.36|  New York|156991.12|\n",
      "|134615.46|     147198.87|      127716.82|California|156122.51|\n",
      "|130298.13|     145530.06|      323876.68|   Florida| 155752.6|\n",
      "|120542.52|     148718.95|      311613.29|  New York|152211.77|\n",
      "|123334.88|     108679.17|      304981.62|California|149759.96|\n",
      "+---------+--------------+---------------+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movie = df_movie.drop('Profit+10000')\n",
    "\n",
    "df_movie.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d52fac",
   "metadata": {},
   "source": [
    "### Renaming column in PySpark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f312d3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+---------------+----------+---------+\n",
      "|R&D Spend|Administration|Marketing Spend|   State_N|   Profit|\n",
      "+---------+--------------+---------------+----------+---------+\n",
      "| 165349.2|      136897.8|       471784.1|  New York|192261.83|\n",
      "| 162597.7|     151377.59|      443898.53|California|191792.06|\n",
      "|153441.51|     101145.55|      407934.54|   Florida|191050.39|\n",
      "|144372.41|     118671.85|      383199.62|  New York|182901.99|\n",
      "|142107.34|      91391.77|      366168.42|   Florida|166187.94|\n",
      "| 131876.9|      99814.71|      362861.36|  New York|156991.12|\n",
      "|134615.46|     147198.87|      127716.82|California|156122.51|\n",
      "|130298.13|     145530.06|      323876.68|   Florida| 155752.6|\n",
      "|120542.52|     148718.95|      311613.29|  New York|152211.77|\n",
      "|123334.88|     108679.17|      304981.62|California|149759.96|\n",
      "+---------+--------------+---------------+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movie = df_movie.withColumnRenamed('State', 'State_N')\n",
    "\n",
    "df_movie.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d52b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
